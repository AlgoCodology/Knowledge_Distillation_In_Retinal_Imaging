{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9763e704",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6568cdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi\n",
    "# model_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a9bc1c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8b33ed5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    413     413    5782\n"
     ]
    }
   ],
   "source": [
    "!ls ./datasets/IDRiD/images/train|wc\n",
    "# !ls ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f03aa813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall numpy\n",
    "# !pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fef3104c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 20:04:40.729312: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import PIL\n",
    "from PIL import ImageFilter\n",
    "# from tensorflow.python import keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model, Model, save_model\n",
    "# import tensorflow_hub as hub\n",
    "# from tensorflow.keras.applications import EfficientNetB4, MobileNetV3Small\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Average\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.applications import *\n",
    "\n",
    "# from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49763d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 2080 Ti, compute capability 7.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 20:04:41.989259: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-07-10 20:04:41.990200: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-07-10 20:04:42.059199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:1b:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.75GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2023-07-10 20:04:42.059239: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-07-10 20:04:42.060796: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-07-10 20:04:42.060853: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-07-10 20:04:42.062231: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-07-10 20:04:42.062495: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-07-10 20:04:42.064025: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-07-10 20:04:42.064869: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-07-10 20:04:42.068134: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-07-10 20:04:42.069112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-07-10 20:04:42.069794: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "# Enable mixed precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "# mixed_precision.set_global_policy('float32')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1992b0bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df=pd.read_csv(\"./datasets/Kaggle/retinopathy_solution.csv\")\n",
    "# df2=pd.read_csv(\"./datasets/Kaggle/trainLabels.csv\")\n",
    "# df=pd.concat([df, df2])\n",
    "# df=df[['image','level']]\n",
    "# df= df.drop_duplicates()\n",
    "# df.to_csv('./datasets/Kaggle/all_labels.csv',header=True, index=False)\n",
    "\n",
    "dataset_path = r'./datasets/'\n",
    "\n",
    "idrid_path = dataset_path + \"IDRiD/\"\n",
    "kaggle_path = dataset_path + \"Kaggle/\"\n",
    "messidor_path = dataset_path + \"Messidor-2/\"\n",
    "\n",
    "idrid_path_train_test = dataset_path + \"IDRiD/images/train/\"\n",
    "kaggle_path_train_test = dataset_path + \"Kaggle/images/\"\n",
    "messidor_path_train_test = dataset_path + \"Messidor-2/images/\"\n",
    "\n",
    "kaggle_csv = \"./datasets/Kaggle/all_labels.csv\"\n",
    "# kaggle_csv = \"./datasets/Kaggle/trainLabels.csv\"\n",
    "idrid_csv = idrid_path + \"a. IDRiD_Disease Grading_Training Labels.csv\"\n",
    "messidor_csv = messidor_path + \"reference.csv\"\n",
    "\n",
    "idrid_columns = ['Image name', 'Retinopathy grade']\n",
    "kaggle_columns = ['image', 'level']\n",
    "messidor_columns = ['i_image','i_adjudicated_dr_grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3586fb30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# folder = r'./datasets/Messidor-2/images/'\n",
    "# files = os.listdir(folder)\n",
    "# files = os.listdir(idrid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bcef3c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(413, 2)\n",
      "(413, 2)\n",
      "Found 413 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define the paths to the image directory and the CSV file\n",
    "train_image_dir: str = idrid_path_train_test\n",
    "# train_image_dir: str = kaggle_path_train_test\n",
    "# train_image_dir: str = messidor_path_train_test\n",
    "# csv_file_train = idrid_path + 'a. IDRiD_Disease Grading_Training Labels.csv'\n",
    "# csv_file_test = idrid_path + 'b. IDRiD_Disease Grading_Testing Labels.csv'\n",
    "csv_file = idrid_csv #kaggle_csv #messidor_csv\n",
    "# Loading the dataset\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# #uncomment for idrid data\n",
    "df = df[idrid_columns]\n",
    "print(df.shape)\n",
    "df['Image name'] = df['Image name'].astype(str) + \".png\"\n",
    "df['Retinopathy grade'] = df['Retinopathy grade'].astype(str)\n",
    "df.rename(columns={'Image name': 'img_name', 'Retinopathy grade': 'label'}, inplace=True)\n",
    "df.dropna(how='all', inplace = True)\n",
    "df = df[df['label'].notnull()]\n",
    "df_shuffled = df.sample(frac=1, random_state=1)\n",
    "df2 = df_shuffled.copy()\n",
    "print(df2.shape)\n",
    "\n",
    "# # #uncomment for kaggle data\n",
    "# df = df[kaggle_columns]\n",
    "# df['image'] = df['image'].astype(str) + \".png\"\n",
    "# df['level'] = df['level'].astype(str)\n",
    "# df.rename(columns={'image': 'img_name', 'level': 'label'}, inplace=True)\n",
    "# df.dropna(how='all', inplace = True)\n",
    "# df = df[df['label'].notnull()]\n",
    "# df_shuffled = df.sample(frac=1, random_state=1)\n",
    "# df2=df_shuffled.iloc[:2048]\n",
    "# df1=df_shuffled.iloc[2048:50048] #including 6000*4 number of elements i.e. max 6000 batches of 4 of which 4500 for training and 1500 for validation\n",
    "# print(df1.head(),df1.shape, df2.head(),df2.shape)\n",
    "\n",
    "\n",
    "##uncomment for messidor data\n",
    "# df = df[messidor_columns]\n",
    "# df['image'] = df['image'].astype(str) + \".png\"\n",
    "# df['level'] = df['level'].astype(str)\n",
    "# df.rename(columns={'i_image': 'img_name', 'i_adjudicated_dr_grade': 'label'}, inplace=True)\n",
    "# df.dropna(how='all', inplace = True)\n",
    "# df = df[df['label'].notnull()]\n",
    "# df_shuffled = df.sample(frac=1, random_state=1)\n",
    "# df2 = df_shuffled.copy()\n",
    "# print(df2.shape)\n",
    "\n",
    "# Creating the image generator\n",
    "# datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "#rotation_range --> minus to plus number of degrees of rotation\n",
    "'''\n",
    "ONE POSSIBLE PREPROCESSING FUNC preprocessing_function=lambda x: np.array(PIL.Image.fromarray(x).filter(ImageFilter.GaussianBlur(radius=2)).getdata()).reshape(data.size[::-1]+(-1,)).astype(np.uint8) if (np.random.rand() < 0.33) else np.array(PIL.Image.fromarray(x).filter(ImageFilter.SHARPEN).getdata()).reshape(data.size[::-1]+(-1,)).astype(np.uint8) if (np.random.rand() < 0.67) else x,\n",
    "'''\n",
    "datagen = ImageDataGenerator(rescale=None, rotation_range=5, zoom_range = 0.05, brightness_range =[0.8,1.2],\n",
    "                             width_shift_range=15, height_shift_range=15, channel_shift_range = 10.0,\n",
    "#                              preprocessing_function = basic_preprocessing_func,\n",
    "                             horizontal_flip=True, validation_split=0.25)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=None)\n",
    "\n",
    "# Creating the training set\n",
    "# train_generator = datagen.flow_from_dataframe(\n",
    "#     dataframe=df1,\n",
    "#     directory=train_image_dir,\n",
    "#     x_col=\"img_name\",\n",
    "#     y_col=\"label\",\n",
    "#     target_size=(512, 512),\n",
    "#     batch_size=16,\n",
    "#     class_mode='categorical',\n",
    "#     subset='training'\n",
    "# )\n",
    "\n",
    "# validation_generator = datagen.flow_from_dataframe(\n",
    "#     dataframe=df1,\n",
    "#     directory=train_image_dir,\n",
    "#     x_col=\"img_name\",\n",
    "#     y_col=\"label\",\n",
    "#     target_size=(512, 512),\n",
    "#     batch_size=16,\n",
    "#     class_mode='categorical',\n",
    "#     subset='validation'\n",
    "# )\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=df2,\n",
    "    directory=train_image_dir,\n",
    "    x_col=\"img_name\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(512, 512),\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df00fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_labels(y_true,y_pred):\n",
    "    original_labels = [0, 1, 2, 3, 4] # original labels\n",
    "    new_labels = [0, 1] # new labels\n",
    "    label_map = {0: 0, 1: 0, 2: 1, 3: 1, 4: 1} # mapping from original labels to new labels\n",
    "    new_y_true = np.zeros((y_true.shape[0], len(new_labels)))\n",
    "    new_y_pred = np.zeros((y_pred.shape[0], len(new_labels)))\n",
    "    for i, row in enumerate(y_true):\n",
    "        for j, val in enumerate(row):\n",
    "            if val == 1:\n",
    "                new_label = label_map[original_labels[j]]\n",
    "                new_y_true[i, new_label] = 1           \n",
    "    for i, row in enumerate(y_pred):\n",
    "        for j, val in enumerate(row):\n",
    "            new_label = label_map[original_labels[j]]\n",
    "            new_y_pred[i, new_label] += val\n",
    "#     print(\"original predictions:\\n\", y_pred)        \n",
    "#     print(\"Aggregated predictions:\\n\", new_y_pred)\n",
    "    return new_y_true, new_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa76e789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, cohen_kappa_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_model(model_name,y_true_original,y_pred_original):\n",
    "#     y_true = tf.keras.utils.to_categorical(test_generator.classes)\n",
    "#     y_pred = model.predict_generator(test_generator)\n",
    "    y_true,y_pred=aggregate_labels(y_true_original,y_pred_original)\n",
    "    print(np.shape(y_true),np.shape(y_pred))\n",
    "    # Compute ROC curve and AUC for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(2):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "#         print(type(fpr[i]),len(fpr[i]),fpr[i])\n",
    "#         print(np.shape(roc_auc[i]))\n",
    "        print(roc_auc[i])\n",
    "        print('_______________________')\n",
    "#         print(type(tpr[i]),len(tpr[i]),tpr[i])\n",
    "    print(len(y_true.ravel()))\n",
    "    # Compute micro-average ROC curve and AUC\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true.ravel(), y_pred.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    # Compute macro-average ROC curve and AUC\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(2)]))\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(2):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "    mean_tpr /= 2\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "    aurocs = roc_auc_score(y_true, y_pred, multi_class = 'ovr', average = 'macro')\n",
    "    print(\"AUROC score for model \"+str(model_name)+\":\", aurocs)\n",
    "    # Plot ROC curves for each class and micro/macro-average\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"], color='deeppink',\n",
    "             lw=lw, label='micro-average ROC curve (AUC = %0.2f)' % roc_auc[\"micro\"])\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"], color='navy',\n",
    "             lw=lw, label='macro-average ROC curve (AUC = %0.2f)' % roc_auc[\"macro\"])\n",
    "    colors = ['blue', 'green', 'red', 'cyan', 'magenta']\n",
    "    for i, color in zip(range(2), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "                 label='ROC curve of class %d (AUC = %0.2f)' % (i, roc_auc[i]))\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('1 - Specificity')\n",
    "    plt.ylabel('Sensitivity')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "def plot_model_binary(model_name,y_true_original,y_pred_original):\n",
    "    \n",
    "    y_true,y_pred=aggregate_labels(y_true_original,y_pred_original)\n",
    "#     print(np.shape(y_true),np.shape(y_pred))\n",
    "    \n",
    "    #saving data to verify manually\n",
    "    l1 = list(y_true[:,0].T)\n",
    "    l2 = list(y_true[:,1].T)\n",
    "    l3 = list(y_pred[:,0].T)\n",
    "    l4 = list(y_pred[:,1].T)\n",
    "    l5 = list(np.where(y_pred[:,1].T>0.5,1,0))\n",
    "    dictionary = {'True 0':l1,'True 1':l2,'Predicted 0':l3,'Predicted 1':l4,'Predicted_Onehot':l5}\n",
    "    pd.DataFrame(dictionary).to_csv('results.csv', index = False, header = True)\n",
    "    \n",
    "    acc_score = accuracy_score(y_true[:,1],np.where(y_pred[:,1]<=0.5,0,1))\n",
    "    print('Accuracy:',acc_score)\n",
    "    \n",
    "    kappa_score = cohen_kappa_score(np.argmax(y_true_original,axis=1 ), np.argmax(y_pred_original,axis=1), weights='quadratic')\n",
    "    print('Quadratic Weighted Kappa:', kappa_score)\n",
    "    \n",
    "    # Compute ROC curve and AUC for each class\n",
    "    # calculate the false positive rate, true positive rate and thresholds using roc_curve\n",
    "    fpr, tpr, _ = roc_curve(y_true[:, 1], y_pred[:, 1])\n",
    "    # calculate the AUC score using roc_auc_score\n",
    "    auc_score = roc_auc_score(y_true[:, 1], y_pred[:, 1])\n",
    "    print(\"AUROC score for model \"+str(model_name)+\":\", auc_score)\n",
    "\n",
    "    # plot the ROC curve\n",
    "    plt.plot(fpr, tpr, label='ROC Curve (AUC = {:.3f})'.format(auc_score))\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', label='Random Guess')\n",
    "    plt.xlabel('FPR ( or 1 minus Specificity)')\n",
    "    plt.ylabel('TPR (or Sensitivity)')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_conf_matrix(model_name, y_true_original,y_pred_original):\n",
    "    \n",
    "    y_true,y_pred=aggregate_labels(y_true_original,y_pred_original)\n",
    "    cm = confusion_matrix(y_true[:,1], np.where(y_pred[:,1]<=0.5,0,1))\n",
    "    # Plot the confusion matrix\n",
    "    plt.matshow(cm, cmap=plt.cm.Blues)\n",
    "    plt.colorbar()\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(i, j, str(cm[i, j]), horizontalalignment='center', verticalalignment='center')\n",
    "    plt.xlabel('True label')\n",
    "    plt.ylabel('Predicted label')\n",
    "    plt.title('Confusion Matrix for model:'+model_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a569da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model_binary(models[0],y_true,y_pred)\n",
    "# plot_conf_matrix(models[0],y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "926e2bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = ['MobNetv3small_0.75_224','EffNet_B4_imagenet']#\n",
    "models = ['EffNet_B4_imagenet','EffNet_B5_imagenet','EffNet_B6_imagenet','EffNet_B7_imagenet','MobNetv3small_0.75_224','MobNetv3small_0.75_classbalanced','MobNetv3small_1.0','EffNet_B5_imagenet_regularized_highdropout','EffNet_B5_imagenet_norescale_sameastfmodel','EffNet_B6_imagenet_norescale_sameastfmodel','EffNet_B7_imagenet_norescale_sameastfmodel','EffNet_B4_imagenet_norescale_sameastfmodel','EffNet_B4_imagenet_classbalanced']\n",
    "# for model in models[8:12]:\n",
    "#     m = load_model('./'+model+'.h5')\n",
    "#     y_true_model = tf.keras.utils.to_categorical(test_generator.classes)\n",
    "#     y_pred_model = m.predict_generator(test_generator)\n",
    "#     plot_model_binary(model,y_true_model,y_pred_model)\n",
    "#     plot_conf_matrix(model,y_true_model,y_pred_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1331b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(test_generator.classes)\n",
    "# y_pred_now[1]\n",
    "# y_true_now[0]\n",
    "# np.argmax(y_pred_now[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bafd2caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_model\n",
    "# x = load_model('./'+models[11]+'.h5')\n",
    "# y_pred_now = x.predict(test_generator)\n",
    "# y_true_now = tf.keras.utils.to_categorical(test_generator.classes)\n",
    "# x = m.predict(test_generator)\n",
    "# y_true_model.shape\n",
    "# np.unique(y_true_model,return_counts=True)\n",
    "# plot_conf_matrix(str(models[4:5]),y_true_model,y_pred_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94a92c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(x,return_counts=True)\n",
    "# models[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b80f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Ensemble Strategy 1: Average\n",
    "# def average_ensemble(models, generator):\n",
    "#     # Make predictions on each model\n",
    "#     y_preds=[]\n",
    "#     for model in models:\n",
    "#         y_preds.append(model.predict_generator(generator))\n",
    "#     # Average the predictions across all models\n",
    "# #     y_ensemble = np.nanmean(np.round(np.floor(y_preds*1000000)/1000000,3), axis=0)\n",
    "# #     # Convert the averaged predictions to class labels\n",
    "# #     y_ensemble = np.argmax(y_preds_avg, axis=1)\n",
    "# #     y_ensemble=y_preds_avg\n",
    "#     return y_preds\n",
    "\n",
    "# #Ensemble Strategy 2: Majority Vote\n",
    "# def majority_vote_ensemble(models, X):\n",
    "#     # Make predictions on each model\n",
    "#     y_preds = [model.predict(X) for model in models]\n",
    "#     # Get the class with the highest probability from each model\n",
    "#     y_preds_argmax = np.argmax(y_preds, axis=2)\n",
    "#     # Compute the mode of the class labels across all models\n",
    "#     y_ensemble = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=y_preds_argmax)\n",
    "#     return y_ensemble\n",
    "\n",
    "# #Ensemble Strategy 3: Max confidence\n",
    "# def max_confidence_ensemble(models, X):\n",
    "#     # Make predictions on each model\n",
    "#     y_preds = [model.predict(X) for model in models]\n",
    "#     # Get the maximum probability of each class from each model\n",
    "#     y_preds_max = np.max(y_preds, axis=2)\n",
    "#     # Compute the maximum probability across all models for each class\n",
    "#     y_ensemble = np.argmax(np.sum(y_preds_max, axis=0))\n",
    "#     return y_ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52f54b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = ['EffNet_B4_imagenet','EffNet_B5_imagenet','EffNet_B6_imagenet',\n",
    "#           'EffNet_B7_imagenet','MobNetv3small_0.75_224','MobNetv3small_0.75_classbalanced',\n",
    "#           'MobNetv3small_1.0','EffNet_B5_imagenet_regularized_highdropout','EffNet_B5_imagenet_norescale_sameastfmodel',\n",
    "#           'EffNet_B6_imagenet_norescale_sameastfmodel','EffNet_B7_imagenet_norescale_sameastfmodel',\n",
    "#           'EffNet_B4_imagenet_norescale_sameastfmodel','EffNet_B4_imagenet_classbalanced']\n",
    "# loaded_models=[]\n",
    "# for i in range(len(models[8:12])):\n",
    "#     var_name = f\"model_{i}\"\n",
    "# #     var_value = models[i]\n",
    "#     var_value = load_model('./'+models[i]+'.h5')\n",
    "#     globals()[var_name] = var_value\n",
    "#     loaded_models.append(globals()[var_name])\n",
    "# # y_pred_ensemble = average_ensemble(loaded_models,test_generator)\n",
    "# # plot_model_binary(model,y_true_ensemble,y_pred_ensemble)\n",
    "# # plot_conf_matrix(model,y_true_ensemble,y_pred_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18235d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EffNet_B4_imagenet_norescale_sameastfmodel_rev',\n",
       " 'EffNet_B5_imagenet_norescale_sameastfmodel_rev',\n",
       " 'EffNet_B6_imagenet_norescale_sameastfmodel_rev',\n",
       " 'EffNet_B7_imagenet_norescale_sameastfmodel_rev']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = ['MobNetv3small_1.0_rev','EffNet_B4_imagenet_norescale_sameastfmodel_rev','EffNet_B5_imagenet_norescale_sameastfmodel_rev','EffNet_B6_imagenet_norescale_sameastfmodel_rev','EffNet_B7_imagenet_norescale_sameastfmodel_rev']\n",
    "models[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae196e7",
   "metadata": {},
   "source": [
    "### TRYING TO SAVE AN ENSEMBLE OUT OF INDIVIDUAL MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c751faa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 20:13:24.878379: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-10 20:13:24.881916: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-07-10 20:13:24.882629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:1b:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.75GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2023-07-10 20:13:24.882671: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-07-10 20:13:24.882692: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-07-10 20:13:24.882702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-07-10 20:13:24.882712: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-07-10 20:13:24.882721: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-07-10 20:13:24.882731: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-07-10 20:13:24.882741: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-07-10 20:13:24.882750: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-07-10 20:13:24.883682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-07-10 20:13:24.883706: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-07-10 20:13:25.455181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-07-10 20:13:25.455210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-07-10 20:13:25.455214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-07-10 20:13:25.456769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10065 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1b:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "# models = ['MobNetv3small_1.0_rev','EffNet_B4_imagenet_norescale_sameastfmodel_rev','EffNet_B5_imagenet_norescale_sameastfmodel_rev','EffNet_B6_imagenet_norescale_sameastfmodel_rev','EffNet_B7_imagenet_norescale_sameastfmodel_rev']\n",
    "# mods=['EffNet_B5_imagenet_norescale_sameastfmodel','EffNet_B6_imagenet_norescale_sameastfmodel',\n",
    "#  'EffNet_B7_imagenet_norescale_sameastfmodel','EffNet_B4_imagenet_norescale_sameastfmodel']\n",
    "\n",
    "# mods = ['EffNet_B4_exp14_NoActivation', 'EffNet_B5_exp15_NoActivation', 'EffNet_B6_exp16_NoActivation']\n",
    "# mods = ['EffNet_B0_imagenet_norescale_sameastfmodel_rev_NoActivation', 'EffNet_B1_imagenet_norescale_sameastfmodel_rev_NoActivation','EffNet_B2_imagenet_norescale_sameastfmodel_rev_NoActivation']\n",
    "# mods = ['EffNetB0_distilled_finalexp21', 'EffNetB1_distilled_finalexp25','EffNetB2_distilled_finalexp26']\n",
    "# mods = models[1:-1]\n",
    "mods=['EffNet_B5_imagenet_Glaucoma','EffNet_B6_imagenet_Glaucoma','EffNet_B7_imagenet_Glaucoma']\n",
    "# Load the individual models and change the names of the layers to be unique\n",
    "model1 = load_model('./models/teacher_experiments/Glaucoma/'+mods[0]+'.h5', compile=False, custom_objects={'tf': tf})\n",
    "model1 = Model(inputs=model1.input, outputs=model1.output, name=mods[0])\n",
    "model2 = load_model('./models/teacher_experiments/Glaucoma/'+mods[1]+'.h5', compile=False, custom_objects={'tf': tf})\n",
    "model2 = Model(inputs=model2.input, outputs=model2.output, name=mods[1])\n",
    "model3 = load_model('./models/teacher_experiments/Glaucoma/'+mods[2]+'.h5', compile=False, custom_objects={'tf': tf})\n",
    "model3 = Model(inputs=model3.input, outputs=model3.output, name=mods[2])\n",
    "# model4 = load_model('./'+mods[3]+'.h5', compile=False, custom_objects={'tf': tf})\n",
    "# model4 = Model(inputs=model4.input, outputs=model4.output, name=mods[3])\n",
    "\n",
    "# Define the input tensor\n",
    "inp = Input(shape=(512, 512, 3), name = 'input')\n",
    "# Get the outputs of the individual models\n",
    "model1_output = model1(inp)\n",
    "model2_output = model2(inp)\n",
    "model3_output = model3(inp)\n",
    "# model4_output = model4(inp)\n",
    "# Average the outputs of the two models\n",
    "ensemble_output = Average(name = 'average')([model1_output, model2_output, model3_output])#, model4_output])\n",
    "\n",
    "# Define the ensemble model\n",
    "# ensemble_model = Model(inputs=inp, outputs=ensemble_output, name = 'ensemble_b0b1_scratch_logits')\n",
    "# ensemble_model = Model(inputs=inp, outputs=ensemble_output, name = 'ensemble_b0b1b2_scratch_logits')\n",
    "ensemble_model = Model(inputs=inp, outputs=ensemble_output, name = 'ensemble_b5b6b7_glaucoma')\n",
    "\n",
    "# Save the ensemble model\n",
    "# save_model(ensemble_model, 'teacher_ensemble_NoActivation.h5')\n",
    "# save_model(ensemble_model, 'student_scratch_ensemble_b0b1_NoActivation.h5')\n",
    "# save_model(ensemble_model, './models/student_experiments/student_scratch_ensemble_b0b1b2_NoActivation.h5')\n",
    "save_model(ensemble_model, './models/teacher_experiments/Glaucoma/ensemble_b5b6b7.h5')\n",
    "\n",
    "# Load the ensemble model for prediction later\n",
    "# loaded_ensemble_model = load_model('teacher_ensemble_b4b5b6.h5')\n",
    "# loaded_ensemble_model = ensemble_model\n",
    "# Use the loaded ensemble model to make predictions\n",
    "# y_true_ensemble = tf.keras.utils.to_categorical(test_generator.classes)\n",
    "# y_pred_ensemble = loaded_ensemble_model.predict_generator(test_generator)\n",
    "# plot_model_binary('Teacher_ensemble',y_true_ensemble,y_pred_ensemble)\n",
    "# plot_conf_matrix('Teacher_ensemble',y_true_ensemble,y_pred_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78bf467b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ensemble_b5b6b7_glaucoma\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "EffNet_B5_imagenet_Glaucoma (Fu (None, 2)            28517625    input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "EffNet_B6_imagenet_Glaucoma (Fu (None, 2)            40964753    input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "EffNet_B7_imagenet_Glaucoma (Fu (None, 2)            64102809    input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average (Average)               (None, 2)            0           EffNet_B5_imagenet_Glaucoma[0][0]\n",
      "                                                                 EffNet_B6_imagenet_Glaucoma[0][0]\n",
      "                                                                 EffNet_B7_imagenet_Glaucoma[0][0]\n",
      "==================================================================================================\n",
      "Total params: 133,585,187\n",
      "Trainable params: 132,877,278\n",
      "Non-trainable params: 707,909\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ensemble_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43db83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model_binary('Teacher_ensemble',y_true_ensemble,y_pred_ensemble)\n",
    "# plot_conf_matrix('Teacher_ensemble',y_true_ensemble,y_pred_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfdc773",
   "metadata": {},
   "source": [
    "### Calculating Ensemble Performance Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8157f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mods=['EffNet_B5_imagenet_norescale_sameastfmodel','EffNet_B6_imagenet_norescale_sameastfmodel',\n",
    " 'EffNet_B7_imagenet_norescale_sameastfmodel','EffNet_B4_imagenet_norescale_sameastfmodel']\n",
    "model1 = load_model('./'+mods[0]+'.h5')\n",
    "model2 = load_model('./'+mods[1]+'.h5')\n",
    "model3 = load_model('./'+mods[2]+'.h5')\n",
    "model4 = load_model('./'+mods[3]+'.h5')\n",
    "y_true_ensemble = tf.keras.utils.to_categorical(test_generator.classes)\n",
    "all_models=[model1,model2,model3,model4]\n",
    "y_pred_ensemble=[]\n",
    "for model in all_models:\n",
    "        y_pred_ensemble.append(model.predict_generator(test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b00e87c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_ensemble = np.mean(y_pred_ensemble, axis=0)\n",
    "y_true_ensemble = tf.keras.utils.to_categorical(test_generator.classes)\n",
    "plot_model_binary('Teacher_ensemble',y_true_ensemble,y_pred_ensemble)\n",
    "plot_conf_matrix('Teacher_ensemble',y_true_ensemble,y_pred_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41a92e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelmobilenet = MobileNetV3Small(input_shape=(512, 512, 3),include_top=False,weights='imagenet',pooling='avg',alpha=1.0)\n",
    "modelmobilenet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be383e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
